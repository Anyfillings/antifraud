# =========================
# Config (–º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è—Ç—å)
# =========================
CH_CONTAINER ?= ch1
CH_DB        ?= antifraud

# –í–ê–ñ–ù–û: –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä–∞–±–æ—Ç–∞–µ–º –ø–æ–¥ default, —á—Ç–æ–±—ã schema –º–æ–≥–ª–∞ –Ω–∞–∫–∞—Ç–∏—Ç—å—Å—è –¥–∞–∂–µ –±–µ–∑ antifraud user
CH_USER      ?= default
CH_PASS      ?= clickhouse

KAFKA_CONTAINER ?= kafka
KAFKA_BOOTSTRAP ?= kafka:9092
KAFKA_TOPIC     ?= transactions
KAFKA_PARTS     ?= 3

CSV_DIR     ?= scripts
CLIENTS_CSV ?= $(CSV_DIR)/clients.csv
ACCOUNTS_CSV?= $(CSV_DIR)/accounts.csv

# =========================
# Compose
# =========================
.PHONY: up down reset logs

up:
	docker compose up -d

down:
	docker compose down

reset:
	docker compose down
	rm -rf ./ch1_volume

logs:
	docker compose logs -f

# =========================
# ClickHouse helpers
# =========================
.PHONY: ping ch
ping:
	curl -sS "http://localhost:8123/?user=$(CH_USER)&password=$(CH_PASS)&query=SELECT%201" ; echo

# =========================
# Schema
# =========================
.PHONY: schema
schema:
	@echo "üìê –ü—Ä–∏–º–µ–Ω—è—é schema –≤ –ë–î $(CH_DB)..."
	docker exec -i $(CH_CONTAINER) clickhouse-client --user $(CH_USER) --password "$(CH_PASS)" --multiquery < sql/schema.antifraud.sql
	@echo "‚úÖ schema –ø—Ä–∏–º–µ–Ω–µ–Ω–∞"

# =========================
# CSV
# =========================
.PHONY: gencsv loadcsv
gencsv:
	@echo "üß™ –ì–µ–Ω–µ—Ä–∏—Ä—É—é CSV..."
	python3 scripts/gen_csv.py
	@echo "‚úÖ CSV –≥–æ—Ç–æ–≤—ã: $(CLIENTS_CSV), $(ACCOUNTS_CSV)"

loadcsv:
	@echo "üê≥ üîï –ó–∞–≥—Ä—É–∂–∞—é CSV –¥–∞–Ω–Ω—ã–µ –≤ ClickHouse ($(CH_DB))..."
	docker exec -i $(CH_CONTAINER) clickhouse-client --user $(CH_USER) --password "$(CH_PASS)" --query \
	"TRUNCATE TABLE $(CH_DB).clients"
	docker exec -i $(CH_CONTAINER) clickhouse-client --user $(CH_USER) --password "$(CH_PASS)" --query \
	"INSERT INTO $(CH_DB).clients FORMAT CSVWithNames" < $(CLIENTS_CSV)

	docker exec -i $(CH_CONTAINER) clickhouse-client --user $(CH_USER) --password "$(CH_PASS)" --query \
	"TRUNCATE TABLE $(CH_DB).accounts"
	docker exec -i $(CH_CONTAINER) clickhouse-client --user $(CH_USER) --password "$(CH_PASS)" --query \
	"INSERT INTO $(CH_DB).accounts FORMAT CSVWithNames" < $(ACCOUNTS_CSV)
	@echo "‚úÖ –í—Å—ë –û–ö"

# =========================
# Kafka + streaming ingest
# =========================
.PHONY: kafka-topic ingest-ddl producer-restart stream-up

kafka-topic:
	@echo "üß© –°–æ–∑–¥–∞—é —Ç–æ–ø–∏–∫ Kafka $(KAFKA_TOPIC)..."
	docker exec -it $(KAFKA_CONTAINER) kafka-topics --bootstrap-server $(KAFKA_BOOTSTRAP) \
		--create --if-not-exists --topic $(KAFKA_TOPIC) --partitions $(KAFKA_PARTS) --replication-factor 1
	@echo "‚úÖ Topic OK"

ingest-ddl:
	@echo "üß± –°–æ–∑–¥–∞—é Kafka ingest —Ç–∞–±–ª–∏—Ü—ã –≤ ClickHouse ($(CH_DB))..."
	docker exec -i $(CH_CONTAINER) clickhouse-client --user $(CH_USER) --password "$(CH_PASS)" --multiquery < sql/transactions_kafka_ingest.sql
	@echo "‚úÖ DDL OK"

producer-restart:
	@echo "üîÅ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—é producer..."
	# –ø–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º, —á—Ç–æ–±—ã —Ç–æ—á–Ω–æ –ø—Ä–∏–º–µ–Ω–∏–ª–∏—Å—å —Å–≤–µ–∂–∏–µ build/env
	docker compose up -d --build --force-recreate producer
	@echo "‚úÖ producer –ø–µ—Ä–µ–∑–∞–ø—É—â–µ–Ω"

stream-up: kafka-topic ingest-ddl producer-restart
	@echo "üöÄ –ó–∞–ø—É—Å–∫–∞—é —Å—Ç—Ä–∏–º–∏–Ω–≥ (kafka + ch1 + producer)..."
	docker compose up -d kafka ch1
	@echo "‚úÖ –ó–∞–ø—É—â–µ–Ω–æ"

# =========================
# Convenience: "–≤—Å—ë —Å—Ä–∞–∑—É"
# =========================
.PHONY: bootstrap
bootstrap: up schema gencsv loadcsv stream-up
	@echo "üéâ –ì–æ—Ç–æ–≤–æ: schema + csv + kafka + producer + ingest"
